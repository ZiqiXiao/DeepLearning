{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using the built model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 0.Prepare the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n0   25    Private  226802          11th                7       Never-married   \n1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n3   44    Private  160323  Some-college               10  Married-civ-spouse   \n4   18          ?  103497  Some-college               10       Never-married   \n\n          occupation relationship   race  gender  capital-gain  capital-loss  \\\n0  Machine-op-inspct    Own-child  Black    Male             0             0   \n1    Farming-fishing      Husband  White    Male             0             0   \n2    Protective-serv      Husband  White    Male             0             0   \n3  Machine-op-inspct      Husband  Black    Male          7688             0   \n4                  ?    Own-child  White  Female             0             0   \n\n   hours-per-week native-country income  \n0              40  United-States  <=50K  \n1              50  United-States  <=50K  \n2              40  United-States   >50K  \n3              40  United-States   >50K  \n4              30  United-States  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>educational-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>gender</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>Private</td>\n      <td>226802</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>89814</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>Local-gov</td>\n      <td>336951</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>Private</td>\n      <td>160323</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>7688</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>?</td>\n      <td>103497</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/adult.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.Logistic regression with varying embedding dimensions, no dropout and Adam optimizer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define a target for logistic regression:\n",
    "df['income_label'] = (df['income'].apply(lambda x: \">50k\" in x)).astype(int)\n",
    "\n",
    "# experiment set up\n",
    "wide_cols = ['age','hours-per-week','education', 'relationship','workclass',\n",
    "             'occupation','native-country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native-country', 'occupation'])\n",
    "embeddings_cols = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                   ('occupation',10),('native-country',10)]\n",
    "continuous_cols = [\"age\",\"hours-per-week\"]\n",
    "target = 'income_label'\n",
    "method = 'logistic'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils.data_utils import prepare_data\n",
    "\n",
    "wd_dataset = prepare_data(df, wide_cols, crossed_cols, embeddings_cols, continuous_cols, target, scale=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# build model\n",
    "# Network set up\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=1 # for logistic and regression\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = None\n",
    "\n",
    "# Build the model. Again you just need to call WideDeep\n",
    "from utils.torch_model import WideDeep\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers, dropout, encoding_dict,n_class)\n",
    "\n",
    "# I have included a compile method if you want to change the fitting method or the optimizer\n",
    "model.compile(method=method, optimizer=\"Adam\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (emb_layer_relationship): Embedding(6, 8)\n",
      "  (emb_layer_occupation): Embedding(15, 10)\n",
      "  (emb_layer_native-country): Embedding(42, 10)\n",
      "  (emb_layer_workclass): Embedding(9, 10)\n",
      "  (emb_layer_education): Embedding(16, 10)\n",
      "  (linear_1): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (linear_2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (output): Linear(in_features=848, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 2 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 3 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 4 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 5 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 6 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 7 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 8 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 9 of 10, Loss: 0.0, accuracy: 1.0\n",
      "Epoch 10 of 10, Loss: 0.0, accuracy: 1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# fit and embedding\n",
    "train_dataset = wd_dataset['train_dataset']\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "\n",
    "# As your usual Sklearn model, simply call fit/predict\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "pred = model.predict(dataset=test_dataset)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(pred, test_dataset.labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'11th': array([ 0.54169065,  0.49417815, -0.05153178, -0.62309986, -1.1947852 ,\n         0.18700363, -0.04341362, -0.33709738,  1.3387694 , -0.1855408 ],\n       dtype=float32),\n 'HS-grad': array([-0.24023673,  0.35751298,  0.5571414 , -0.8167463 ,  0.06322116,\n         0.8080706 ,  0.30061978, -0.43353292,  0.4794336 ,  0.61343956],\n       dtype=float32),\n 'Assoc-acdm': array([ 0.17981398, -0.50020593,  1.0978745 , -0.18372947, -1.0036201 ,\n        -0.14446326,  0.5564964 ,  0.34890598,  1.4261824 , -2.2461843 ],\n       dtype=float32),\n 'Some-college': array([-0.6781258 ,  0.19341134, -0.7988352 ,  0.6347257 , -2.088572  ,\n         1.8912214 , -3.1393185 , -0.5383918 , -0.1377146 ,  1.4895263 ],\n       dtype=float32),\n '10th': array([-0.36800134, -0.4938993 ,  1.024859  ,  0.09277789, -0.9246003 ,\n        -0.85090435, -1.4173918 ,  0.5473981 , -0.6436034 , -0.6557604 ],\n       dtype=float32),\n 'Prof-school': array([ 0.55081147,  0.9792929 ,  0.6659547 , -0.87960064,  0.7151308 ,\n         0.23310444, -0.23238203, -1.1960979 , -0.7015007 ,  1.218412  ],\n       dtype=float32),\n '7th-8th': array([-1.3221952 ,  0.2372607 , -1.5975353 ,  1.20132   ,  0.23422725,\n         1.419177  , -1.1111634 , -0.58784163,  0.60064787,  1.4729837 ],\n       dtype=float32),\n 'Bachelors': array([ 1.179001  , -0.5274188 , -2.0425375 ,  1.2859566 ,  0.7967446 ,\n        -1.1024826 , -0.13002606, -0.7788145 ,  0.88481474, -0.17071874],\n       dtype=float32),\n 'Masters': array([ 1.6504179 , -0.485495  , -0.24979584, -0.61697847, -0.29660946,\n         0.946717  , -0.95396763,  0.6844378 , -0.4538135 ,  0.7358842 ],\n       dtype=float32),\n 'Doctorate': array([ 0.95362604,  0.32997173,  0.41065395, -0.30847326,  0.28390715,\n         0.7163743 , -0.42272726,  0.42710304, -0.57966053,  0.21428208],\n       dtype=float32),\n '5th-6th': array([-0.12784979, -0.4021114 , -0.70414686,  0.48448837,  0.4428972 ,\n        -1.1566024 , -0.03657568,  0.33379623,  1.6485165 , -0.41807443],\n       dtype=float32),\n 'Assoc-voc': array([ 0.30145162, -1.8490645 , -1.320932  , -0.4684436 , -0.31511667,\n         0.90369916,  1.1288306 ,  0.6189375 ,  0.7005978 ,  1.2943826 ],\n       dtype=float32),\n '9th': array([-1.5535314 , -0.33535933,  0.9046003 ,  0.08488785, -0.50100756,\n         0.63470787,  0.11273883, -0.58017665, -0.29282913, -0.37450123],\n       dtype=float32),\n '12th': array([ 0.6234389 , -0.5819453 ,  0.89105994, -0.8452452 ,  1.2367469 ,\n         0.01188108,  0.94356745,  0.8059993 ,  1.744545  , -1.2699901 ],\n       dtype=float32),\n '1st-4th': array([-0.6359867 ,  0.00569232,  0.4220185 ,  0.4580668 ,  0.1443241 ,\n        -0.39626044,  1.0885652 , -1.0615488 , -0.28978446, -1.1623236 ],\n       dtype=float32),\n 'Preschool': array([ 2.1559558 ,  0.7244481 , -0.03799343,  0.92551166, -1.5795395 ,\n         0.19173078, -1.0417361 , -0.31822667,  2.8554566 ,  0.09246638],\n       dtype=float32)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_embeddings('education')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.Multiclass classification with fixed embedding dimensions(10), varying dropout and RMSProp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (emb_layer_relationship): Embedding(6, 10)\n",
      "  (emb_layer_workclass): Embedding(9, 10)\n",
      "  (emb_layer_native-country): Embedding(42, 10)\n",
      "  (emb_layer_occupation): Embedding(15, 10)\n",
      "  (emb_layer_education): Embedding(16, 10)\n",
      "  (linear_1): Linear(in_features=51, out_features=100, bias=True)\n",
      "  (linear_1_drop): Dropout(p=0.5, inplace=False)\n",
      "  (linear_2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (linear_2_drop): Dropout(p=0.2, inplace=False)\n",
      "  (output): Linear(in_features=847, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Let's define age groups\n",
    "age_groups = [0, 25, 50, 90]\n",
    "age_labels = range(len(age_groups) - 1)\n",
    "df['age_group'] = pd.cut(df['age'], age_groups, labels=age_labels)\n",
    "\n",
    "# Set the experiment\n",
    "wide_cols = ['hours-per-week','education', 'relationship','workclass',\n",
    "             'occupation','native-country','gender']\n",
    "crossed_cols = (['education', 'occupation'], ['native-country', 'occupation'])\n",
    "embeddings_cols = ['education', 'relationship','workclass','occupation','native-country']\n",
    "continuous_cols = [\"hours-per-week\"]\n",
    "target = 'age_group'\n",
    "method = 'multiclass'\n",
    "\n",
    "wd_dataset = prepare_data(df,wide_cols,crossed_cols,embeddings_cols,continuous_cols,target,scale=True,def_dim=10)\n",
    "\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=3\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = [0.5, 0.2]\n",
    "\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers,dropout,encoding_dict,n_class)\n",
    "model.compile(method=method, optimizer=\"RMSprop\")\n",
    "\n",
    "# Let's have a look to the model\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoziqi/Desktop/Code/deep-learning/Wide&Deep/PyTorch/utils/torch_model.py:155: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation(self.output(wide_deep_input))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10, Loss: 0.887, accuracy: 0.6785\n",
      "Epoch 2 of 10, Loss: 0.91, accuracy: 0.6875\n",
      "Epoch 3 of 10, Loss: 0.848, accuracy: 0.6903\n",
      "Epoch 4 of 10, Loss: 0.797, accuracy: 0.6927\n",
      "Epoch 5 of 10, Loss: 1.133, accuracy: 0.6944\n",
      "Epoch 6 of 10, Loss: 1.072, accuracy: 0.6974\n",
      "Epoch 7 of 10, Loss: 0.972, accuracy: 0.6976\n",
      "Epoch 8 of 10, Loss: 0.721, accuracy: 0.7002\n",
      "Epoch 9 of 10, Loss: 0.718, accuracy: 0.6993\n",
      "Epoch 10 of 10, Loss: 0.633, accuracy: 0.6998\n",
      "\n",
      " [[2.9131240e-01 7.0733297e-01 1.3546958e-03]\n",
      " [4.1371289e-01 5.8624840e-01 3.8669281e-05]\n",
      " [9.9740285e-01 2.5710945e-03 2.6083995e-05]\n",
      " ...\n",
      " [7.5831962e-01 2.1754092e-01 2.4139451e-02]\n",
      " [6.7187249e-11 9.9999678e-01 3.1666616e-06]\n",
      " [1.3452404e-07 9.9978524e-01 2.1469337e-04]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = wd_dataset['train_dataset']\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "\n",
    "# The model object also has a predict_proba method in case you want probabilities instead of class\n",
    "pred = model.predict_proba(test_dataset)\n",
    "print('\\n {}'.format(pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Linear regression with varying embedding dimensions and varying dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (emb_layer_relationship): Embedding(6, 8)\n",
      "  (emb_layer_workclass): Embedding(9, 10)\n",
      "  (emb_layer_native-country): Embedding(42, 10)\n",
      "  (emb_layer_occupation): Embedding(15, 10)\n",
      "  (emb_layer_education): Embedding(16, 10)\n",
      "  (linear_1): Linear(in_features=49, out_features=100, bias=True)\n",
      "  (linear_1_drop): Dropout(p=0.5, inplace=False)\n",
      "  (linear_2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (linear_2_drop): Dropout(p=0.2, inplace=False)\n",
      "  (output): Linear(in_features=847, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment\n",
    "wide_cols = ['hours-per-week','education', 'relationship','workclass',\n",
    "             'occupation','native-country','gender']\n",
    "crossed_cols  = (['education', 'occupation'], ['native-country', 'occupation'])\n",
    "embeddings_cols  = [('education',10), ('relationship',8), ('workclass',10),\n",
    "                    ('occupation',10),('native-country',10)]\n",
    "continuous_cols = [\"hours-per-week\"]\n",
    "target = 'age'\n",
    "method = 'regression'\n",
    "\n",
    "# Prepare the dataset\n",
    "wd_dataset = prepare_data(df, wide_cols,crossed_cols,embeddings_cols,continuous_cols,target)\n",
    "\n",
    "wide_dim = wd_dataset['train_dataset'].wide.shape[1]\n",
    "n_class=1\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']\n",
    "hidden_layers = [100,50]\n",
    "dropout = [0.5, 0.2]\n",
    "model = WideDeep(wide_dim,embeddings_input,continuous_cols,deep_column_idx,hidden_layers,dropout,encoding_dict,n_class)\n",
    "model.compile(method=method)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10, Loss: 361.227\n",
      "Epoch 2 of 10, Loss: 120.188\n",
      "Epoch 3 of 10, Loss: 185.024\n",
      "Epoch 4 of 10, Loss: 169.754\n",
      "Epoch 5 of 10, Loss: 139.843\n",
      "Epoch 6 of 10, Loss: 167.409\n",
      "Epoch 7 of 10, Loss: 147.47\n",
      "Epoch 8 of 10, Loss: 53.157\n",
      "Epoch 9 of 10, Loss: 177.697\n",
      "Epoch 10 of 10, Loss: 138.325\n",
      "\n",
      " RMSE: 11.311551226299784\n"
     ]
    }
   ],
   "source": [
    "train_dataset = wd_dataset['train_dataset']\n",
    "model.fit(dataset=train_dataset, n_epochs=10, batch_size=64)\n",
    "\n",
    "test_dataset  = wd_dataset['test_dataset']\n",
    "pred = model.predict(test_dataset)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"\\n RMSE: {}\".format(np.sqrt(mean_squared_error(pred, test_dataset.labels))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}